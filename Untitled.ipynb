{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5cfd41-325e-45e5-8cdf-0a7a66418ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--target TARGET] [--data-dir DATA_DIR]\n",
      "                             [--out OUT] [--lookback-days LOOKBACK_DAYS]\n",
      "                             [--stdout]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/yueuy/Library/Jupyter/runtime/kernel-c4542292-b548-4623-8811-000912c0f3a0.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "make_predictions.py\n",
    "\n",
    "Produce one line of predictions in the required format:\n",
    "\n",
    "\"YYYY-MM-DD\", L1_00, ..., L29_23, PH_1, ..., PH_29, PD_1, ..., PD_29\n",
    "\n",
    "- \"YYYY-MM-DD\" is the *run date* (target_date - 1 day), matching the project spec.\n",
    "- L values are hourly loads (MW), rounded to integers.\n",
    "- PH values are the predicted peak hour (0..23) via a softmax over the 24 hourly loads.\n",
    "- PD values are 0/1 indicating a predicted \"peak day\" (heuristic; see Task 3).\n",
    "\n",
    "References: course spec for the format and schedule.  # see slides\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# Canonical 29-zone order (L1..L29)\n",
    "# RTO is excluded; alias USI->UGI, AE->AECO handled in loader.\n",
    "# -------------------------------\n",
    "ZONES_29: List[str] = [\n",
    "    \"AECO\",\"AEPAPT\",\"AEPIMP\",\"AEPKPT\",\"AEPOPT\",\n",
    "    \"AP\",\"BC\",\"CE\",\"DAY\",\"DEOK\",\"DOM\",\"DPLCO\",\"DUQ\",\"EASTON\",\n",
    "    \"EKPC\",\"JC\",\"ME\",\"OE\",\"OVEC\",\"PAPWR\",\"PE\",\"PEPCO\",\"PLCO\",\n",
    "    \"PN\",\"PS\",\"RECO\",\"SMECO\",\"UGI\",\"VMEU\"\n",
    "]\n",
    "\n",
    "ALIAS_MAP = {\"USI\": \"UGI\", \"AE\": \"AECO\"}\n",
    "\n",
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def _iter_hrl_files(data_dir: str):\n",
    "    # Preferred flat naming\n",
    "    found = False\n",
    "    for y in range(2016, 2026):\n",
    "        fp = os.path.join(data_dir, f\"hrl_load_metered_{y}.csv\")\n",
    "        if os.path.exists(fp):\n",
    "            found = True\n",
    "            yield fp\n",
    "    if found:\n",
    "        return\n",
    "    # Fallback: recursive search under data_dir\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for fn in files:\n",
    "            if fn.startswith(\"hrl_load_metered_\") and fn.endswith(\".csv\"):\n",
    "                yield os.path.join(root, fn)\n",
    "\n",
    "def _default_target_date_str() -> str:\n",
    "    # Tomorrow in UTC (sufficient for this script)\n",
    "    return (datetime.utcnow() + timedelta(days=1)).date().isoformat()\n",
    "\n",
    "# -------------------------------\n",
    "# Load all *prior* data\n",
    "# -------------------------------\n",
    "def load_prior_hist(target_date_str: str, data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load rows strictly before target_date across all yearly CSVs.\n",
    "    Harmonize zone names, drop RTO aggregate.\n",
    "    \"\"\"\n",
    "    target_date = pd.to_datetime(target_date_str).date()\n",
    "    frames = []\n",
    "    usecols = [\"datetime_beginning_ept\", \"load_area\", \"mw\"]\n",
    "\n",
    "    for fp in _iter_hrl_files(data_dir):\n",
    "        df = pd.read_csv(fp, usecols=usecols, parse_dates=[\"datetime_beginning_ept\"])\n",
    "        df[\"load_area\"] = df[\"load_area\"].replace(ALIAS_MAP)\n",
    "        df = df[df[\"load_area\"] != \"RTO\"]\n",
    "        df[\"date_ept\"] = df[\"datetime_beginning_ept\"].dt.date\n",
    "        df = df[df[\"date_ept\"] < target_date]\n",
    "        frames.append(df[[\"datetime_beginning_ept\", \"load_area\", \"mw\"]])\n",
    "\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No HRL CSVs found under '{data_dir}'. Expected files like hrl_load_metered_2016.csv\"\n",
    "        )\n",
    "\n",
    "    hist = pd.concat(frames, ignore_index=True)\n",
    "    hist = hist.sort_values([\"load_area\", \"datetime_beginning_ept\"]).rename(\n",
    "        columns={\"datetime_beginning_ept\": \"ts\"}\n",
    "    )\n",
    "    return hist.reset_index(drop=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Task 1: hourly loads (baseline)\n",
    "# -------------------------------\n",
    "def forecast_hourly(hist: pd.DataFrame,\n",
    "                    zones: List[str],\n",
    "                    lookback_days: int | None = None) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Baseline: for each (zone, hour), use the mean of that hour over prior data.\n",
    "    If lookback_days is set, restrict to that recent window.\n",
    "    \"\"\"\n",
    "    if hist.empty:\n",
    "        return {z: np.zeros(24, float) for z in zones}\n",
    "\n",
    "    h = hist.copy()\n",
    "    h[\"hour\"] = h[\"ts\"].dt.hour\n",
    "\n",
    "    if lookback_days:\n",
    "        cutoff = h[\"ts\"].max().normalize() - pd.Timedelta(days=int(lookback_days))\n",
    "        h = h[h[\"ts\"] >= cutoff]\n",
    "\n",
    "    by_zh = h.groupby([\"load_area\", \"hour\"], observed=True)[\"mw\"].mean()\n",
    "\n",
    "    out: Dict[str, np.ndarray] = {}\n",
    "    for z in zones:\n",
    "        z_mean = float(h.loc[h[\"load_area\"] == z, \"mw\"].mean()) if (h[\"load_area\"] == z).any() else 0.0\n",
    "        out[z] = np.array([by_zh.get((z, hr), z_mean) for hr in range(24)], dtype=float)\n",
    "    return out\n",
    "\n",
    "# -------------------------------\n",
    "# Task 2: softmax + peak hour\n",
    "# -------------------------------\n",
    "def softmax(vec: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(vec, dtype=float)\n",
    "    T = max(float(x.std()), 1.0)  # stabilize; avoid one-hot\n",
    "    z = (x - x.max()) / T\n",
    "    e = np.exp(z)\n",
    "    s = e.sum()\n",
    "    return e / s if s > 0 else np.ones_like(x) / len(x)\n",
    "\n",
    "def peak_hour_from_softmax(zone_hourly: Dict[str, np.ndarray]) -> Dict[str, int]:\n",
    "    return {z: int(np.argmax(softmax(v))) for z, v in zone_hourly.items()}\n",
    "\n",
    "# -------------------------------\n",
    "# Task 3: peak-day flag (0/1)\n",
    "# -------------------------------\n",
    "def peakday_flags(hist: pd.DataFrame,\n",
    "                  zones: List[str],\n",
    "                  zone_hourly: Dict[str, np.ndarray],\n",
    "                  trailing_days: int = 180,\n",
    "                  q: float = 0.80) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    PD=1 if the predicted daily peak (max of 24 hourly forecasts) >= q-quantile\n",
    "    of trailing daily peaks from prior data; else PD=0.\n",
    "    \"\"\"\n",
    "    if hist.empty:\n",
    "        return {z: 0 for z in zones}\n",
    "\n",
    "    d = hist.copy()\n",
    "    d[\"date\"] = d[\"ts\"].dt.normalize()\n",
    "    # Use trailing window for stability\n",
    "    end_date = d[\"date\"].max()\n",
    "    start_date = end_date - pd.Timedelta(days=int(trailing_days))\n",
    "    d = d[(d[\"date\"] >= start_date) & (d[\"date\"] <= end_date)]\n",
    "\n",
    "    daily = d.groupby([\"load_area\", \"date\"], observed=True)[\"mw\"].max().reset_index()\n",
    "\n",
    "    out: Dict[str, int] = {}\n",
    "    for z in zones:\n",
    "        vals = daily.loc[daily[\"load_area\"] == z, \"mw\"].to_numpy()\n",
    "        thr = (vals.max() if vals.size < 5 else float(np.quantile(vals, q)))\n",
    "        pred_peak = float(np.max(zone_hourly[z]))\n",
    "        out[z] = int(pred_peak >= thr)\n",
    "    return out\n",
    "\n",
    "# -------------------------------\n",
    "# Build the one-line output\n",
    "# -------------------------------\n",
    "def build_single_line(run_date_str: str,\n",
    "                      zones: List[str],\n",
    "                      zone_hourly: Dict[str, np.ndarray],\n",
    "                      peak_hour: Dict[str, int],\n",
    "                      peak_day: Dict[str, int]) -> str:\n",
    "    fields: List[str] = [f'\"{run_date_str}\"']\n",
    "    # 29Ã—24 hourly loads (rounded ints), zone-major, hour-minor\n",
    "    for z in zones:\n",
    "        fields.extend(str(int(round(v))) for v in zone_hourly[z])\n",
    "    # 29 PH values\n",
    "    fields.extend(str(int(peak_hour[z])) for z in zones)\n",
    "    # 29 PD flags\n",
    "    fields.extend(str(int(peak_day[z])) for z in zones)\n",
    "    return \", \".join(fields)\n",
    "\n",
    "# -------------------------------\n",
    "# main()\n",
    "# -------------------------------\n",
    "def main(argv: List[str] | None = None) -> None:\n",
    "    ap = argparse.ArgumentParser(description=\"Make one-line PJM predictions in class format.\")\n",
    "    ap.add_argument(\"--target\", default=None,\n",
    "                    help=\"Target forecast date (YYYY-MM-DD). Default: tomorrow (UTC).\")\n",
    "    ap.add_argument(\"--data-dir\", default=\".\",\n",
    "                    help=\"Directory containing hrl_load_metered_YYYY.csv files.\")\n",
    "    ap.add_argument(\"--out\", default=None,\n",
    "                    help=\"Output CSV path. Default: predictions_<run_date>.csv (run_date = target-1).\")\n",
    "    ap.add_argument(\"--lookback-days\", type=int, default=None,\n",
    "                    help=\"Optional recent window for Task 1; if omitted, use all prior data.\")\n",
    "    ap.add_argument(\"--stdout\", action=\"store_true\",\n",
    "                    help=\"If set, print ONLY the required one-line output to stdout.\")\n",
    "    args = ap.parse_args(argv)\n",
    "\n",
    "    target_date_str = args.target or _default_target_date_str()\n",
    "    target_date = pd.to_datetime(target_date_str).normalize()\n",
    "    run_date_str = (target_date - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    out_path = args.out or f\"predictions_{run_date_str}.csv\"\n",
    "\n",
    "    # 1) Load all prior data\n",
    "    hist = load_prior_hist(target_date_str, args.data_dir)\n",
    "\n",
    "    # 2) Task 1\n",
    "    zone_hourly = forecast_hourly(hist, ZONES_29, lookback_days=args.lookback_days)\n",
    "\n",
    "    # 3) Task 2\n",
    "    peak_hour = peak_hour_from_softmax(zone_hourly)\n",
    "\n",
    "    # 4) Task 3\n",
    "    peak_day = peakday_flags(hist, ZONES_29, zone_hourly, trailing_days=180, q=0.80)\n",
    "\n",
    "    # 5) Compose one line and write\n",
    "    line = build_single_line(run_date_str, ZONES_29, zone_hourly, peak_hour, peak_day)\n",
    "\n",
    "    if args.stdout:\n",
    "        # Print ONLY the one required line (no header, no extra text)\n",
    "        print(line)\n",
    "    else:\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
